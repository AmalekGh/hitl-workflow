{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HITL-SCC_Workflow Iteration I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iteration represents the first step of the Scientific Content Creation Workflow, whiche represents a user interactive pipeline to systematically extract knowledge from a corpus of scientific literature. This should help the user have better insights into key contents of the corpus.\n",
    "\n",
    "This notebook provides a step-by-step, instruction based approach from setting up the corpus to extracting and representing knowledge relevant to the user.\n",
    "\n",
    "The first task is to support the user in the process of retrieving a set of relevant literature, and to better represent the knowledge for the user.\n",
    "\n",
    "This iterative process requires little to no programming prior knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![setup](<media/MA003.jpg>)\n",
    "![knowledge](<media/Frame9.jpg>)\n",
    "![publish](<media/Frame10.jpg>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the described process, this notebook runs tools and functions that are specifically implemented to query and scrape different digital libraries. A requirements file (requirements.txt) is predefined to install all necessary packages. \n",
    "\n",
    "This requires a Jupyter environment that runs any version of python 3.\n",
    "\n",
    "In order to install the different packages, we only need to run the next cell one time. If you already run it once on your machine, just ignore it and don't run it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two approaches are developed to extract a corpus of PDFs. One is for the case of not having a set of scientfic literature, the second is for the case of having one. Note that either step 1. or step 2. should be used to extract a corpus of PDFs, and not both. If you already have a set of papers in a Zotero collection, please skip to step 2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Corpus mining**\n",
    "\n",
    "The initial step is to formulate a search query that aligns with the desired research objective. In this task, we can use a large language model (LLM) to extract relevant keywords that will be used in the process of querying scientific databases. \n",
    "\n",
    "The second step is inputing the search query that will be fed to different scraping models. This step represents the core of this iteration. \n",
    "\n",
    "The used tools in this step are: \n",
    "-  **LLM** (Optional for formulating the search query)\n",
    "-  Modified **[RESP](https://github.com/monk1337/resp)** Arxiv-module \n",
    "- **Semantic Scholar API**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user formulates a search query and copies this in the space between the single quotation marks below in the next cell. We use the variable named **papers_search_query**\n",
    "\n",
    "An example that can be used as a search query is: *large language models for effective knowledge extraction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bef314e2ef444c8d338b57b84fc342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Your search query here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "input_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Your search query here',\n",
    "    disabled=False\n",
    ")\n",
    "def save_input(change):\n",
    "    global papers_search_query\n",
    "    papers_search_query = change['new']\n",
    "\n",
    "input_widget.observe(save_input, names='value')\n",
    "\n",
    "display(input_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell allows the user to predefine the size limit of the corpus to be created. The variable **limit** holds to maximum size of papers to be downloaded from each source. \n",
    "\n",
    "Note that many search results don't include an open acess to PDFs.\n",
    "\n",
    "The next cell has 50 as a predefined value ( 50 pdf as a maximum from each different source ).\n",
    "\n",
    "The user is able to modify this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b795245c82f4ceaa94210753285d65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, description='Documents Limit:', layout=Layout(width='400px'), min=1, style=SliderStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from widgets.widgets_util import DocumentLimitSlider\n",
    "slider_widget = DocumentLimitSlider()\n",
    "get_value_func = slider_widget.display_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, is to define the sources of our corpus. Multiple digital libraries and scientific databases can be accessed and queried. \n",
    "\n",
    "Here we create a list of sources, that the user can adapt. Note that the names of the sources are given between quotations and separated by a coma \",\" as in the example below. The elements in the list are responsible of specifying which and how many sources we take in consieration.\n",
    "\n",
    "**Note** This version only supports querying **Arxiv** and **Semantic Scholar**. Later version will include further sources.\n",
    "\n",
    "Current possible entries for the list: \n",
    "- \"Arxiv\"\n",
    "- \"Semantic Scholar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eedf8c8c97b417990134606f7735af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Enter a new option')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29d876c478b44f4a84aefff2a44943b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Add Option', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d8a87bcc084a3381cea8c4a062ff5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Delete Selected Options', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5472f9afefe64d2ebdc86ccf3920e8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='Arxiv'), Checkbox(value=False, description='Semantic Scholar…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from widgets.widgets_util import DynamicSourceList\n",
    "dynamic_checkbox_list = DynamicSourceList()\n",
    "dynamic_checkbox_list.display_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = dynamic_checkbox_list.get_selected_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sources' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marxiv_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Arxiv\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msemanticscholar_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SemanticScholar\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m \u001b[43msources\u001b[49m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArxiv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      6\u001b[0m         arxiv_instance \u001b[38;5;241m=\u001b[39m Arxiv()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sources' is not defined"
     ]
    }
   ],
   "source": [
    "from util.arxiv_api import Arxiv\n",
    "from util.semanticscholar_util import SemanticScholar\n",
    "\n",
    "for source in sources:\n",
    "    if source == \"Arxiv\":\n",
    "        arxiv_instance = Arxiv()\n",
    "        arxiv_instance.download_pdf(papers_search_query, limit)\n",
    "            \n",
    "    elif source == \"Semantic Scholar\":\n",
    "        semanticscholar_instance = SemanticScholar()\n",
    "        semanticscholar_instance.download_pdfs(papers_search_query, limit)\n",
    "    else:\n",
    "        print(\"Unknown Identifier specified in the sources\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Corpus extraction from Zotero**\n",
    "\n",
    "This approach is for the case of having a Zotero collections that we want to investigate. This will result in creating a corpus of PDFs locally saved on the users local machine. For this, we use Zotero's API. \n",
    "\n",
    "This step requires a unique Zotero API Key, the library ID, the library type, and the collection's ID. This information can be found/set up in your personal zotero account.\n",
    "\n",
    "The used tools in this step are: \n",
    "- **Zotero** and **Zotero API**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "Paper has no accessible PDF.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "PDF Downloaded.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Paper has no accessible PDF.\n",
      "Download completed. Found documents were downloaded\n"
     ]
    }
   ],
   "source": [
    "from pyzotero import zotero\n",
    "import os\n",
    "from util.zotero_util import ZoteroUtil\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv('ZOTERO_API_KEY')\n",
    "LIBRARY_ID = os.getenv('LIBRARY_ID')\n",
    "LIBRARY_TYPE = os.getenv('LIBRARY_TYPE')\n",
    "COLLECTIONS = os.getenv('COLLECTION')\n",
    "\n",
    "\n",
    "zot = zotero.Zotero(LIBRARY_ID, LIBRARY_TYPE, API_KEY)\n",
    "\n",
    "download_directory = 'zotero_pdfs'\n",
    "os.makedirs(download_directory, exist_ok=True)\n",
    "\n",
    "items = zot.collection_items(COLLECTIONS)\n",
    "for item in items:\n",
    "    if 'url' in item['data']:\n",
    "        ZoteroUtil.download_pdf(item['data']['url'], item['data']['key'])\n",
    "        \n",
    "        \n",
    "print(\"Download completed. Found documents were downloaded\")\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
