{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HITL-SCC_Workflow Iteration I_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step of the Iteration represents the processing of the extracted text and preparing the input for the Large language model.\n",
    "This step is considered the core of the RAG application (Retrieval augmented generation). Here, we use the context of the paper to leverage the ability\n",
    "of the models to extract relevant parts of the paper and to perform context-based analysis. This part also creates a data model based on user input.\n",
    "\n",
    "![rag_pipeline](<media/rag_pipeline.jpg>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We list the tools used in this part: \n",
    "-  **Ollama**\n",
    "\n",
    "Ollama is a service that provides easy access to large language Models and other tools needed for the embedding, computing and generating text.\n",
    "It allows us in this workflow to communicate with the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Defining Data Model**\n",
    "\n",
    "This steps allows the user to define the data model. \n",
    "A data model in this context is a structured set of properties that should serve as an input in order to communicate with the corpus. \n",
    "The properties can include multiple parts of a paper as well as specific values relevant to the user. \n",
    "\n",
    "For now, we define a data model to be a list that contains one (or multiple sets) of the following properties: \n",
    "- Title\n",
    "- Theme\n",
    "- Keywords\n",
    "- Task\n",
    "- Evaluation Approach\n",
    "- Future Directions\n",
    "- Theories\n",
    "- Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00abaae7d4d44d49b5bd3f63944b38ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Enter a new option')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb83d3e26564190ab92e17c52e64bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Add Option', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500b4625682b4146977ae9954620df07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Delete Selected Options', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cf608568e24ad5a493e5f495edbec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='Title'), Checkbox(value=False, description='Theme'), Checkboâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from widgets.widgets_util import DynamicCheckboxList\n",
    "dynamic_checkbox_list = DynamicCheckboxList()\n",
    "dynamic_checkbox_list.display_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title', 'Keywords', 'Evaluation Approach']\n"
     ]
    }
   ],
   "source": [
    "print(dynamic_checkbox_list.get_selected_options())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Text chunking**\n",
    "\n",
    "In this part, we compute the text of the documents in order to create a meaningful start point for the communication with the documents.\n",
    "\n",
    "To better identify information present in the text, a semantic chunking method is used in order to create smaller parts of the text. \n",
    "\n",
    "The result of this step is creating semantically conntected units of text that are easier to process.\n",
    "\n",
    "\n",
    "![rag_pipeline](<media/semantic.jpg>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Similarity search & Prompting**\n",
    "\n",
    "This parts consists of retrieving the related information to the provided data model. \n",
    "In this step, we search for the top k chunks of text that result of a vector search between each chunk and the respective query created out of the data model.\n",
    "\n",
    "The top k chunks are then used in the prompt given to the large language model in order to provide context in this application.\n",
    "\n",
    "Running the code cell below outputs the LLM-generated text, which represent the identified data out of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronous Example\n",
    "from mistralai import Mistral\n",
    "import os\n",
    "from embedding.document_util import DocumentUtil\n",
    "folder_path = 'zotero_pdfs'\n",
    "results= []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith('.pdf'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        print(f\"Processing PDF file: {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "        test_doc = DocumentUtil.get_text_without_references(DocumentUtil, file_path)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        INSTRUCTIONS:\n",
    "        You are a tool that extracts information from a given document based on Key values. The given document represents a research paper.\n",
    "        Given the DOCUMENT below and the KEY VALUES, and using no prior knowledge, extract the respective information.\n",
    "        Your answer should contain the extracted information without further explanation.\n",
    "        If the information is not present in the text, return NOT FOUND.\n",
    "        In The text should be formatted in the following way: \n",
    "        ### Key value : Information\n",
    "        ----------------------------------------------\n",
    "        DOCUMENT: \n",
    "        {test_doc}\n",
    "        ----------------------------------------------\n",
    "        KEY VALUES:\n",
    "            Title - Keywords - Evaluation approach - Conclusion - Future directions - Theories - Dataset.\n",
    "        ----------------------------------------------\n",
    "        ANSWER: \n",
    "        \"\"\"\n",
    "        \n",
    "        s = Mistral(\n",
    "            api_key=\"OgYSLOA5ZyDRBWbdSP0wKMKf68z6v9Rq\",\n",
    "        )\n",
    "        \n",
    "        res = s.chat.complete(model=\"mistral-large-latest\", messages=[\n",
    "            {\n",
    "                \"content\": prompt,\n",
    "                \"role\": \"user\",\n",
    "            },\n",
    "        ])\n",
    "        \n",
    "        if res is not None:\n",
    "            # Run for around 8 Minutes for a corpus of around 30 Papers.\n",
    "            pass\n",
    "        print(res.choices[0].message.content)\n",
    "        results.append(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df_list = []\n",
    "for result in results:\n",
    "    lines = result.splitlines()\n",
    "    example_values = []\n",
    "    information_list = []\n",
    "        \n",
    "    for line in lines:\n",
    "        match = re.match(r\"^###\\s*(.*?)[:-]\\s*(.*)$\", line)\n",
    "        if match:\n",
    "            example_value = match.group(1).strip()\n",
    "            information = match.group(2).strip()\n",
    "            example_values.append(example_value)\n",
    "            information_list.append(information)\n",
    "        \n",
    "        # Create a DataFrame\n",
    "    df = pd.DataFrame({'Key value': example_values, 'Information': information_list})\n",
    "    df_list.append(df)\n",
    "    print(df)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"zotero_pdfs\"\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "file_names = [f for f in file_names if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "transformed_dataframes = []\n",
    "\n",
    "for df in df_list:\n",
    "    pivoted_df = df.set_index('Key value').T\n",
    "    transformed_dataframes.append(pivoted_df)\n",
    "\n",
    "combined_df = pd.concat(transformed_dataframes, ignore_index=True)\n",
    "\n",
    "combined_df['File Name'] = file_names\n",
    "columns = ['File Name'] + [col for col in combined_df.columns if col != 'File Name']\n",
    "combined_df = combined_df[columns]\n",
    "\n",
    "combined_df.to_csv('combined_output_with_filenames.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "tags": "hide-input"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
