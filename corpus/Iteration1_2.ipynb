{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HITL-SCC_Workflow Iteration I_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step of the Iteration represents the processing of the extracted text and preparing the input for the Large language model.\n",
    "This step is considered the core of the RAG application (Retrieval augmented generation). Here, we use the context of the paper to leverage the ability\n",
    "of the models to extract relevant parts of the paper and to perform context-based analysis. This part also creates a data model based on user input.\n",
    "\n",
    "![rag_pipeline](<media/rag_pipeline.jpg>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We list the tools used in this part: \n",
    "-  **Ollama**\n",
    "\n",
    "Ollama is a service that provides easy access to large language Models and other tools needed for the embedding, computing and generating text.\n",
    "It allows us in this workflow to communicate with the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Defining Data Model**\n",
    "\n",
    "This steps allows the user to define the data model. \n",
    "A data model in this context is a structured set of properties that should serve as an input in order to communicate with the corpus. \n",
    "The properties can include multiple parts of a paper as well as specific values relevant to the user. \n",
    "\n",
    "For now, we define a data model to be a list that contains one (or multiple sets) of the following properties: \n",
    "- Title\n",
    "- Theme\n",
    "- Keywords\n",
    "- Task\n",
    "- Evaluation Approach\n",
    "- Future Directions\n",
    "- Theories\n",
    "- Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49eb0e8e54a4ff99b980b062e84ee7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Enter a new option')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d399788e32546bb90f7a09b3d7f7d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Add Option', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fbf9ef277049019ad7bf1d92836320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Delete Selected Options', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e0cea034514d189edd629020159521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='Title'), Checkbox(value=False, description='Theme'), Checkboâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from widgets.widgets_util import DynamicCheckboxList\n",
    "dynamic_checkbox_list = DynamicCheckboxList()\n",
    "dynamic_checkbox_list.display_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Text chunking**\n",
    "\n",
    "In this part, we compute the text of the documents in order to create a meaningful start point for the communication with the documents.\n",
    "\n",
    "To better identify information present in the text, a semantic chunking method is used in order to create smaller parts of the text. \n",
    "\n",
    "The result of this step is creating semantically conntected units of text that are easier to process.\n",
    "\n",
    "\n",
    "![rag_pipeline](<media/semantic.jpg>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Similarity search & Prompting**\n",
    "\n",
    "This parts consists of retrieving the related information to the provided data model. \n",
    "In this step, we search for the top k chunks of text that result of a vector search between each chunk and the respective query created out of the data model.\n",
    "\n",
    "The top k chunks are then used in the prompt given to the large language model in order to provide context in this application.\n",
    "\n",
    "Running the code cell below outputs the LLM-generated text, which represent the identified data out of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from embedding.document_util import DocumentUtil\n",
    "\n",
    "splitted_text = DocumentUtil.text_splitter(DocumentUtil, './')\n",
    "sentences = [{'sentence': x, 'index': i} for i,x in enumerate(splitted_text)]\n",
    "comb_sentences = DocumentUtil.combine_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunking.chunks_util import ChunksUtil\n",
    "from embedding.embedding_util import EmbeddingUtil\n",
    "\n",
    "embeddings = EmbeddingUtil.ollama_embed_combined_sentences(EmbeddingUtil, comb_sentences)\n",
    "for i, sentence in enumerate(comb_sentences):\n",
    "    sentence['combined_sentence_embedding'] = embeddings[i]\n",
    "distances, sentences = ChunksUtil.calculate_cosine_distances(comb_sentences)\n",
    "split_distances = ChunksUtil.get_split_indices(distances)\n",
    "chunks_final = ChunksUtil.split_using_distances(split_distances, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of two processes, namely the online shop process described in [16] and the hotel service process from the PET data set [2].\n"
     ]
    }
   ],
   "source": [
    "from embedding.embedding_util import EmbeddingUtil \n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from llms.llm_util import LlmUtil\n",
    "from prompting.prompts import Prompts\n",
    "\n",
    "top_k_chunks = EmbeddingUtil.compute_top_k_ollama(EmbeddingUtil, chunks_final, \"Evaluation Approach of this paper:\")\n",
    "prompt = Prompts.get_prompt_2(Prompts, top_k_chunks, \"What is the Evaluation Approach in this paper ?\")\n",
    "response = LlmUtil.prompt_ollama(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- --------------\n",
      "absl-py                      2.1.0\n",
      "aiohappyeyeballs             2.4.0\n",
      "aiohttp                      3.10.5\n",
      "aiosignal                    1.3.1\n",
      "annotated-types              0.7.0\n",
      "anyio                        4.4.0\n",
      "argon2-cffi                  23.1.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "arrow                        1.3.0\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "async-lru                    2.0.4\n",
      "async-timeout                4.0.3\n",
      "attrs                        24.2.0\n",
      "babel                        2.16.0\n",
      "beautifulsoup4               4.12.3\n",
      "bibtexparser                 1.4.1\n",
      "bleach                       6.1.0\n",
      "blis                         0.7.11\n",
      "cachetools                   5.5.0\n",
      "catalogue                    2.0.10\n",
      "certifi                      2024.8.30\n",
      "cffi                         1.17.1\n",
      "charset-normalizer           3.3.2\n",
      "click                        8.1.7\n",
      "cloudpathlib                 0.19.0\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.2\n",
      "confection                   0.1.5\n",
      "contourpy                    1.3.0\n",
      "cryptography                 43.0.1\n",
      "cycler                       0.12.1\n",
      "cymem                        2.0.8\n",
      "debugpy                      1.8.5\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "en-core-web-sm               3.7.1\n",
      "exceptiongroup               1.2.2\n",
      "executing                    2.1.0\n",
      "faiss-cpu                    1.8.0.post1\n",
      "fastjsonschema               2.20.0\n",
      "feedparser                   6.0.11\n",
      "filelock                     3.16.0\n",
      "flatbuffers                  24.3.25\n",
      "fonttools                    4.53.1\n",
      "fqdn                         1.5.1\n",
      "frozenlist                   1.4.1\n",
      "fsspec                       2024.9.0\n",
      "gast                         0.4.0\n",
      "google-auth                  2.34.0\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "greenlet                     3.0.3\n",
      "grpcio                       1.66.1\n",
      "h11                          0.14.0\n",
      "h5py                         3.11.0\n",
      "httpcore                     1.0.5\n",
      "httpx                        0.27.2\n",
      "huggingface-hub              0.24.6\n",
      "idna                         3.8\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.27.0\n",
      "ipywidgets                   8.1.5\n",
      "isoduration                  20.11.0\n",
      "jedi                         0.19.1\n",
      "Jinja2                       3.1.4\n",
      "joblib                       1.4.2\n",
      "json5                        0.9.25\n",
      "jsonpatch                    1.33\n",
      "jsonpointer                  3.0.0\n",
      "jsonschema                   4.23.0\n",
      "jsonschema-specifications    2023.12.1\n",
      "jupyter                      1.1.1\n",
      "jupyter_client               8.6.2\n",
      "jupyter-console              6.6.3\n",
      "jupyter_core                 5.7.2\n",
      "jupyter-events               0.10.0\n",
      "jupyter-lsp                  2.2.5\n",
      "jupyter_server               2.14.2\n",
      "jupyter_server_terminals     0.5.3\n",
      "jupyterlab                   4.2.5\n",
      "jupyterlab_pygments          0.3.0\n",
      "jupyterlab_server            2.27.3\n",
      "jupyterlab_widgets           3.0.13\n",
      "keras                        2.10.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "kiwisolver                   1.4.7\n",
      "langchain                    0.2.16\n",
      "langchain-core               0.2.38\n",
      "langchain-text-splitters     0.2.4\n",
      "langcodes                    3.4.0\n",
      "langsmith                    0.1.116\n",
      "language_data                1.2.0\n",
      "libclang                     18.1.1\n",
      "load-dotenv                  0.1.0\n",
      "marisa-trie                  1.2.0\n",
      "Markdown                     3.7\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   2.1.5\n",
      "matplotlib                   3.9.2\n",
      "matplotlib-inline            0.1.7\n",
      "mdurl                        0.1.2\n",
      "mistune                      3.0.2\n",
      "mpmath                       1.3.0\n",
      "multidict                    6.0.5\n",
      "murmurhash                   1.0.10\n",
      "nbclient                     0.10.0\n",
      "nbconvert                    7.16.4\n",
      "nbformat                     5.10.4\n",
      "nest-asyncio                 1.6.0\n",
      "networkx                     3.3\n",
      "nltk                         3.9.1\n",
      "notebook                     7.2.2\n",
      "notebook_shim                0.2.4\n",
      "numpy                        1.26.4\n",
      "oauthlib                     3.2.2\n",
      "ollama                       0.3.2\n",
      "opt-einsum                   3.3.0\n",
      "orjson                       3.10.7\n",
      "overrides                    7.7.0\n",
      "packaging                    24.1\n",
      "pandocfilters                1.5.1\n",
      "parso                        0.8.4\n",
      "pdfminer                     20191125\n",
      "pdfminer.six                 20240706\n",
      "pillow                       10.4.0\n",
      "pip                          24.2\n",
      "platformdirs                 4.3.1\n",
      "preshed                      3.0.9\n",
      "prometheus_client            0.20.0\n",
      "prompt_toolkit               3.0.47\n",
      "protobuf                     3.19.6\n",
      "psutil                       6.0.0\n",
      "pure_eval                    0.2.3\n",
      "pyasn1                       0.6.0\n",
      "pyasn1_modules               0.4.0\n",
      "pycparser                    2.22\n",
      "pycryptodome                 3.20.0\n",
      "pydantic                     2.9.0\n",
      "pydantic_core                2.23.2\n",
      "Pygments                     2.18.0\n",
      "pyparsing                    3.1.4\n",
      "python-dateutil              2.9.0.post0\n",
      "python-dotenv                1.0.1\n",
      "python-json-logger           2.0.7\n",
      "pytz                         2024.1\n",
      "pywin32                      306\n",
      "pywinpty                     2.0.13\n",
      "PyYAML                       6.0.2\n",
      "pyzmq                        26.2.0\n",
      "pyzotero                     1.5.20\n",
      "referencing                  0.35.1\n",
      "regex                        2024.7.24\n",
      "requests                     2.32.3\n",
      "requests-oauthlib            2.0.0\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rich                         13.8.0\n",
      "rpds-py                      0.20.0\n",
      "rsa                          4.9\n",
      "safetensors                  0.4.5\n",
      "scikit-learn                 1.5.1\n",
      "scipy                        1.14.1\n",
      "Send2Trash                   1.8.3\n",
      "sentence-transformers        3.0.1\n",
      "setuptools                   72.1.0\n",
      "sgmllib3k                    1.0.0\n",
      "shellingham                  1.5.4\n",
      "six                          1.16.0\n",
      "smart-open                   7.0.4\n",
      "sniffio                      1.3.1\n",
      "soupsieve                    2.6\n",
      "spacy                        3.7.6\n",
      "spacy-legacy                 3.0.12\n",
      "spacy-loggers                1.0.5\n",
      "SQLAlchemy                   2.0.34\n",
      "srsly                        2.4.8\n",
      "stack-data                   0.6.3\n",
      "sympy                        1.13.2\n",
      "tenacity                     8.5.0\n",
      "tensorboard                  2.10.1\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.10.1\n",
      "tensorflow-estimator         2.10.0\n",
      "tensorflow-hub               0.16.1\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "tensorflow-text              2.10.0\n",
      "termcolor                    2.4.0\n",
      "terminado                    0.18.1\n",
      "tf-keras                     2.15.0\n",
      "thinc                        8.2.5\n",
      "threadpoolctl                3.5.0\n",
      "tinycss2                     1.3.0\n",
      "tokenizers                   0.19.1\n",
      "tomli                        2.0.1\n",
      "torch                        2.4.1\n",
      "tornado                      6.4.1\n",
      "tqdm                         4.66.5\n",
      "traitlets                    5.14.3\n",
      "transformers                 4.44.2\n",
      "typer                        0.12.5\n",
      "types-python-dateutil        2.9.0.20240906\n",
      "typing_extensions            4.12.2\n",
      "tzdata                       2024.1\n",
      "uri-template                 1.3.0\n",
      "urllib3                      2.2.2\n",
      "vectordb2                    0.1.9\n",
      "wasabi                       1.1.3\n",
      "wcwidth                      0.2.13\n",
      "weasel                       0.4.1\n",
      "webcolors                    24.8.0\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.8.0\n",
      "Werkzeug                     3.0.4\n",
      "wheel                        0.43.0\n",
      "widgetsnbextension           4.0.13\n",
      "wrapt                        1.16.0\n",
      "yarl                         1.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Jupyter core packages...\n",
      "IPython          : 8.27.0\n",
      "ipykernel        : 6.29.5\n",
      "ipywidgets       : 8.1.5\n",
      "jupyter_client   : 8.6.2\n",
      "jupyter_core     : 5.7.2\n",
      "jupyter_server   : 2.14.2\n",
      "jupyterlab       : 4.2.5\n",
      "nbclient         : 0.10.0\n",
      "nbconvert        : 7.16.4\n",
      "nbformat         : 5.10.4\n",
      "notebook         : 7.2.2\n",
      "qtconsole        : not installed\n",
      "traitlets        : 5.14.3\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
